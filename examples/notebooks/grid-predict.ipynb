{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "import itertools\n",
    "import numpy\n",
    "import scipy\n",
    "import scipy.special\n",
    "import time\n",
    "import random\n",
    "\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "from crocodile.simulate import simulate_point\n",
    "from crocodile.antialias import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some grid characteristics. Only theta is actually important here, the rest is just decides the range of the example $u/v$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 0.1\n",
    "lam = 18000\n",
    "grid_size = int(theta * lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_oversample(ff, Qpx, s=None, P = 1):\n",
    "    \"\"\"\n",
    "    Takes a farfield pattern and creates an oversampled convolution\n",
    "    function.\n",
    "\n",
    "    If the far field size is smaller than N*Qpx, we will pad it. This\n",
    "    essentially means we apply a sinc anti-aliasing kernel by default.\n",
    "\n",
    "    :param ff: Far field pattern\n",
    "    :param Qpx: Factor to oversample by -- there will be Qpx x Qpx convolution arl\n",
    "    :param s: Size of convolution function to extract\n",
    "    :returns: Numpy array of shape [ov, ou, v, u], e.g. with sub-pixel\n",
    "      offsets as the outer coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    # Pad the far field to the required pixel size\n",
    "    N = ff.shape[0]\n",
    "    if s is None: s = N\n",
    "    padff = pad_mid(ff, N*Qpx*P)\n",
    "\n",
    "    # Obtain oversampled uv-grid\n",
    "    af = fft(padff)\n",
    "\n",
    "    # Extract kernels\n",
    "    return extract_oversampled(extract_mid(af, N*Qpx), Qpx, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine $u/v$ gridding function to use. Three choices here - trivial, Sze-Tan's version and PSWF. `x0` decides how much of the image coordinate space we can actually use without errors rising.\n",
    "\n",
    "We use that to calculate the appropriate grid step length `du` for good accuracy in our target field of view `theta`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_size = 2047\n",
    "aa_over = 256\n",
    "aa_support = 10\n",
    "aa_x0 = 0.375\n",
    "aa_mode = 0\n",
    "aa_szetan = False\n",
    "aa_nifty = True\n",
    "aa_parameter = numpy.pi*aa_support/2\n",
    "if aa_support == 1:\n",
    "    print(\"Using trivial gridder\")\n",
    "    aa_gcf = numpy.ones((aa_over, aa_support))\n",
    "    def aa(x): return numpy.ones_like(x)\n",
    "elif aa_nifty:\n",
    "    print(\"Using exponential of semi-circle with beta=%d\" % (aa_support))\n",
    "    aa = numpy.exp(aa_parameter*(numpy.sqrt(1-(2*coordinates(grid_size))**2)-1))\n",
    "    aa_gcf = kernel_oversample(aa, aa_over, aa_support) / grid_size\n",
    "    def aa(x):\n",
    "        return numpy.exp(aa_parameter*(numpy.sqrt(1-(2*x)**2)-1))\n",
    "elif aa_szetan:\n",
    "    print(\"Using Sze-Tan's gridder with R=%d, x_0=%g\" % (aa_support//2, aa_x0))\n",
    "    aa_gcf = sze_tan_gridder(aa_support//2, aa_x0, aa_over)\n",
    "    def aa(x):\n",
    "        return sze_tan_grid_correction_gen(aa_support//2, aa_x0, x)\n",
    "    print(\"Mean error:\", sze_tan_mean_error(aa_support//2, aa_x0))\n",
    "else:\n",
    "    print(\"Using PSWF with mode %d and parameter %g\" % (aa_mode, aa_parameter))\n",
    "    aa = scipy.special.pro_ang1(aa_mode, aa_mode, aa_parameter, 2*coordinates(grid_size))[0]\n",
    "    aa_gcf = kernel_oversample(aa, aa_over, aa_support) / grid_size\n",
    "    def aa(x):\n",
    "        return scipy.special.pro_ang1(aa_mode, aa_mode, aa_parameter, 2*x)[0]\n",
    "    \n",
    "# Calculate appropriate step length to give us full accuracy for a field of view of size theta\n",
    "du = du_opt = aa_x0/(theta/2)\n",
    "print(\"Optimal du =\", du)\n",
    "\n",
    "# Plot gridding function\n",
    "plt.rcParams['figure.figsize'] = 10, 5\n",
    "r = numpy.arange(-aa_over*(aa_support//2), aa_over*((aa_support+1)//2)) / aa_over\n",
    "plt.semilogy(du_opt*r, numpy.abs(numpy.transpose(aa_gcf).flatten()));\n",
    "#plt.semilogy(du_opt*r, numpy.transpose(aa2_gcf).flatten().real);\n",
    "plt.xticks(du_opt*numpy.arange(-(aa_support//2), ((aa_support+1)//2)+1))\n",
    "plt.grid(True);plt.xlabel('u/v [$\\lambda$]');plt.title('$u/v$ Gridder');plt.show()\n",
    "\n",
    "# Plot grid correction function\n",
    "theta_x0 = theta/aa_x0/2\n",
    "x = coordinates(101)\n",
    "plt.semilogy(theta*x/aa_x0/2, aa(x));\n",
    "plt.title('$u/v$ Grid correction');plt.grid(True);plt.xlabel('l [1]')\n",
    "plt.axvspan(theta/2, theta_x0/2, color='lightgray', hatch='x', alpha=0.5)\n",
    "plt.axvspan(-theta/2, -theta_x0/2, color='lightgray', hatch='x', alpha=0.5)\n",
    "plt.annotate('(unused)', xy=((theta+theta_x0)/4,0.9), ha='center', color='gray')\n",
    "plt.annotate('(unused)', xy=(-(theta+theta_x0)/4,0.9), ha='center', color='gray');\n",
    "#plt.semilogy(theta*coordinates(grid_size)/aa_x0/2, anti_aliasing_function(grid_size, aa_mode, aa_parameter));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_support_w = 8\n",
    "aa_x0_w = 0.125\n",
    "aa_szetan_w = False\n",
    "aa_nifty_w = False\n",
    "aa_parameter_w = numpy.pi*aa_support_w/2\n",
    "if aa_support_w == 1:\n",
    "    print(\"Using trivial gridder\")\n",
    "    aa_gcf_w = numpy.ones((aa_over, aa_support_w))\n",
    "    def aa_w(x): return numpy.ones_like(x)\n",
    "elif aa_nifty_w:\n",
    "    print(\"Using exponential of semi-circle with beta=%d\" % (aa_support))\n",
    "    aa_gcf_w = kernel_oversample(\n",
    "        numpy.exp(aa_support*(numpy.sqrt(1-(2*coordinates(grid_size))**2)-1)),\n",
    "        aa_over, aa_support) / grid_size\n",
    "    def aa_w(x):\n",
    "        return numpy.exp(aa_support*(numpy.sqrt(1-(2*x)**2)-1))\n",
    "elif aa_szetan_w:\n",
    "    print(\"Using Sze-Tan's gridder with R=%d, x_0=%g\" % (aa_support_w//2, aa_x0_w))\n",
    "    aa_gcf_w = sze_tan_gridder(aa_support_w//2, aa_x0_w, aa_over)\n",
    "    def aa_w(x):\n",
    "        return sze_tan_grid_correction_gen(aa_support_w//2, aa_x0_w, x)\n",
    "    print(\"Mean error:\", sze_tan_mean_error(aa_support_w//2, aa_x0_w))\n",
    "else:\n",
    "    aa_w = anti_aliasing_function(grid_size, 0, aa_parameter_w)\n",
    "    aa_gcf_w = kernel_oversample(aa_w, aa_over, aa_support_w) / grid_size\n",
    "    def aa_w(x):\n",
    "        return scipy.special.pro_ang1(aa_mode, aa_mode, aa_parameter_w, 2*x)[0]\n",
    "\n",
    "# Calculate appropriate step length to give us full accuracy for a field of view of size theta\n",
    "max_n = 1.0 - numpy.sqrt(1.0 - 2*(theta/2)**2)\n",
    "print(\"max_n =\", max_n)\n",
    "dw = dw_opt = aa_x0_w / max_n\n",
    "print(\"Optimal dw =\", dw)\n",
    "\n",
    "# Plot gridding function\n",
    "plt.rcParams['figure.figsize'] = 10, 5\n",
    "r = numpy.arange(-aa_over*(aa_support_w//2), aa_over*((aa_support_w+1)//2)) / aa_over\n",
    "plt.semilogy(dw_opt*r, numpy.transpose(aa_gcf_w).flatten().real);\n",
    "plt.xticks(dw_opt*numpy.arange(-(aa_support_w//2), ((aa_support_w+1)//2)+1))\n",
    "plt.grid(True); plt.xlabel('w [$\\lambda$]'); plt.title('$w$ Gridder'); plt.show()\n",
    "\n",
    "x = coordinates(101)\n",
    "plt.semilogy(max_n*x/aa_x0_w, aa_w(x));\n",
    "plt.title('$w$ Grid correction'); plt.grid(True); plt.xlabel('$n$ [1]');\n",
    "max_n_x0 = max_n/aa_x0_w/2\n",
    "plt.axvspan(max_n, max_n_x0, color='lightgray', hatch='x', alpha=0.5)\n",
    "plt.axvspan(-max_n, -max_n_x0, color='lightgray', hatch='x', alpha=0.5)\n",
    "plt.annotate('(unused)', xy=((max_n+max_n_x0)/2,0.9), ha='center', color='gray')\n",
    "plt.annotate('(unused)', xy=(-(max_n+max_n_x0)/2,0.9), ha='center', color='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate some sources on the sky. We use a random pattern to make reasonably sure that we are not hand-picking a good sky pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Npt = 500\n",
    "points = theta * (numpy.random.rand(Npt,2)-0.5)\n",
    "\n",
    "#points = list(theta/10 * numpy.array(list(itertools.product(range(-5, 6), range(-5, 6)))))\n",
    "#points.append((theta/3,0))\n",
    "#points = numpy.array(points)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 8, 8\n",
    "plt.scatter(points[:,0], points[:,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up code to predict visibilities - either directly or by visibilities weighted by the grid correction and offset in a grid-like fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict(dist_uvw, du=du_opt, dw=dw_opt, apply_aa = False, apply_aa_w = False):\n",
    "    # Get image coordinates\n",
    "    ls, ms = numpy.transpose(points)\n",
    "    ns = numpy.sqrt(1.0 - ls**2 - ms**2) - 1\n",
    "    # Evaluate grid correction functions in uv & w\n",
    "    aas = numpy.ones(len(ls))\n",
    "    if apply_aa:\n",
    "        aas *= aa(du*ls) * aa(du*ms)\n",
    "    if apply_aa_w:\n",
    "        aas *= aa_w(dw*ns)\n",
    "    # Now simulate points, dividing out grid correction\n",
    "    vis = 0\n",
    "    for l,m, a in zip(ls, ms, aas):\n",
    "        vis += simulate_point(dist_uvw, l, m) / a\n",
    "    return vis\n",
    "\n",
    "def predict_grid(u,v,w,ov_u,ov_v,ov_w,du=du_opt, dw=dw_opt, visualise=False):\n",
    "    \n",
    "    # Generate offsets that we are going to sample at\n",
    "    ius, ivs, iws = numpy.meshgrid(numpy.arange(aa_support), numpy.arange(aa_support), numpy.arange(aa_support_w))\n",
    "    dus = du*(ius.flatten()-(aa_support//2)+ov_u/aa_over)\n",
    "    dvs = du*(ivs.flatten()-(aa_support//2)+ov_v/aa_over)\n",
    "    dws = dw*(iws.flatten()-(aa_support_w//2)+ov_w/aa_over)\n",
    "    \n",
    "    # Get grid convolution function for offsets\n",
    "    aas = aa_gcf[ov_u,ius.flatten()] * aa_gcf[ov_v,ivs.flatten()] * aa_gcf_w[ov_w,iws.flatten()]\n",
    "\n",
    "    # Add offsets to all uvw coordinates\n",
    "    us = numpy.array(u)[:,numpy.newaxis] + dus[numpy.newaxis,:]\n",
    "    vs = numpy.array(v)[:,numpy.newaxis] + dvs[numpy.newaxis,:]\n",
    "    ws = numpy.array(w)[:,numpy.newaxis] + dws[numpy.newaxis,:]\n",
    "    \n",
    "    # Visualise sampling pattern?\n",
    "    if visualise:\n",
    "        ax = plt.subplot(111, projection='3d')\n",
    "        ax.scatter(us,vs,ws, color='red');\n",
    "        ax.set_xlabel('u'); ax.set_ylabel('v'); ax.set_zlabel('w')\n",
    "\n",
    "    # Predict visibilities\n",
    "    vis = predict(numpy.transpose([us.flatten(),vs.flatten(),ws.flatten()]),\n",
    "                  du=du, dw=dw, apply_aa=True, apply_aa_w=True).reshape(us.shape)\n",
    "    \n",
    "    # Convolve with gridder, sum up\n",
    "    return numpy.sum(vis * aas[numpy.newaxis,:], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test the performance of the sampling over a wide variety of parameters. Note that `u`,`v` and `w` do not actually matter too much, but we get into trouble quickly by increasing `du` or `dw` -- that is when we start using our gridder for inaccurate image coordinates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(u=(-lam/2,lam/2,0.1),v=(-lam/2,lam/2,0.1),w=(-lam/2,lam/2,0.1),\n",
    "          ov_u=(0,aa_over-1), ov_v=(0,aa_over-1), ov_w=(0,aa_over-1),\n",
    "          du=(du_opt/10,du_opt*2,du_opt/10), dw=(dw_opt/10,dw_opt*2,dw_opt/10))\n",
    "def test(u=0,v=0,w=0, ov_u=0,ov_v=0,ov_w=0, du=du_opt, dw=dw_opt):\n",
    "    vis = predict(numpy.transpose([[u],[v],[w]]))\n",
    "    print(\"Direct: \", vis[0])\n",
    "    vis_sum = predict_grid([u],[v],[w],ov_u,ov_v,ov_w,du,dw)\n",
    "    print(\"Grid:   \", vis_sum[0])\n",
    "    print(\"Error:  \", numpy.abs(vis[0]-vis_sum[0]) / numpy.sqrt(Npt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a quick statistic by feeding in a good couple of points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "us = lam * (numpy.random.rand(N)-0.5)\n",
    "vs = lam * (numpy.random.rand(N)-0.5)\n",
    "ws = lam * (numpy.random.rand(N)-0.5)\n",
    "ov_u = random.randint(0, aa_over-1)\n",
    "ov_v = random.randint(0, aa_over-1)\n",
    "ov_w = random.randint(0, aa_over-1)\n",
    "vis = predict(numpy.transpose([us,vs,ws]))\n",
    "grid_vis = predict_grid(us,vs,ws,ov_u,ov_v,ov_w)\n",
    "diff = numpy.abs(vis-grid_vis)\n",
    "mean_err = numpy.sqrt(numpy.mean(diff**2)) / numpy.mean(numpy.abs(vis))\n",
    "print(\"Mean error:\", mean_err)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
